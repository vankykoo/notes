# 多线程（补充）

## 一、volatile关键字

### 1）如何保证变量的可见性

在Java中，volatile关键字可以保证变量的可见性，如果我们将变量声明为**volatile**，这就指示JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/jmm.png)

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/jmm2.png)

volatile关键字其实并非是Java语言特有的，在C语言里也有，它最原始的意义就是禁用CPU缓存。如果我们将一个变量用volatile修饰，这就指示编译器，这个变量是共享不稳定的，每次使用它都到主存中进行读取。

**volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。**





### 2）如何禁止指令重排序

在Java中，volatile关键字除了可以保证变量的可见性，还有一个重要的作用就是**防止JVM的指令重排序**。如果我们将变量声明为volatile，在对这个变量进行读写操作的时候，会<u>通过插入特点的内存屏障的方式</u>来禁止指令重排序。

> **指令重排序**是指编译器或CPU为了优化程序的执行性能而对指令进行重新排序的一种手段。重排序会带来可见性问题，所以在多线程开发中必须要关注并规避重排序。

在Java中，Unsafe类提供了三个开箱即用的内存屏障相关的方法，屏蔽了系统操作底层的差异。

```java
public native void loadFence();
public native void storeFence();
public native void fullFence();
```

理论上来说，你通过这三个方法也可以实现和volatile禁止重排序一样的效果，只是会麻烦一些。

下面以一个常见的面试题讲解一下volatile关键字禁止指令重排序的效果。

面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”

```java
public class Singleton {

    private volatile static Singleton uniqueInstance;

    private Singleton() {
    }

    public  static Singleton getUniqueInstance() {
       //先判断对象是否已经实例过，没有实例化过才进入加锁代码
        if (uniqueInstance == null) {
            //类对象加锁
            synchronized (Singleton.class) {
                if (uniqueInstance == null) {
                    uniqueInstance = new Singleton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

`uniqueInstance`采用`volatile`关键字修饰也是很有必要的，`uniqueInstance = new Singleton();`这段代码其实分为三步执行：

①为`uniqueInstance`分配内存空间

②初始化`uniqueInstance`

③将`uniqueInstance`指向分配的内存地址。

但是由于JVM具有指令重排的特性，执行顺序有可能变成①--③--②。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程T1执行了①和③，此时T2调用`getUniqueInstance()`后发现`uniqueInstance`不为空，因此返回`uniqueInstance`，但此时`uniqueInstance`还未被初始化。



### 3）volatile可以保证原子性么

**volatile**关键字能保证变量的可见性，不能保证对变量的操作是原子性的。

> **原子性**指的是一个操作要么全部完成，要么全部不完成，不会结束在中间某个环节。在数据库中，原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响

```java
public class VolatoleAtomicityDemo {
    public volatile static int inc = 0;

    public void increase() {
        inc++;
    }

    public static void main(String[] args) throws InterruptedException {
        ExecutorService threadPool = Executors.newFixedThreadPool(5);
        VolatoleAtomicityDemo volatoleAtomicityDemo = new VolatoleAtomicityDemo();
        for (int i = 0; i < 5; i++) {
            threadPool.execute(() -> {
                for (int j = 0; j < 500; j++) {
                    volatoleAtomicityDemo.increase();
                }
            });
        }
        // 等待1.5秒，保证上面程序执行完成
        Thread.sleep(1500);
        System.out.println(inc);
        threadPool.shutdown();
    }
}
```

正常情况下，运行上面的代码理应输出2500，但你真正运行了上面的代码之后，你会发现每次输出结果都小于2500.

如果**volatile**能保证`inc++`操作的原子性的话，每个线程中对`inc`变量自增完之后，其他线程可以立即看到修改后的值，5个线程分别进行了500次操作，那么最终`inc`的值应该是5*500=2500.

很多人会误认为自增操作`inc++`是原子性的，实际上，`inc++`其实是一个复合操作，包括三步：

①读取inc的值

②对inc加1

③将inc的值写回内存

`volatile`是无法保证这三个操作是有原子性的，有可能导致下面这种情况出现：

1、线程1对inc进行读取操作之后，还未对其进行修改。线程2又读取了inc的值并对其进行修改（+1），再将inc的值写回内存。

2、线程2操作完毕之后，线程1对`inc`的值进行修改（+1），再将inc的值写回内存。

这也就导致两个线程分别对`inc`进行了一次自增操作后，`inc`实际上只增加了1.

其实，如果想要保证上面的代码运行正常也非常简单。可以用`synchronized`、`Lock`或者`AtomicInteger`都可以。

使用`synchronized`改进：

```java
public synchronized void increase() {
    inc++;
}
```

使用`AtomicInteger`改进：

```java
public AtomicInteger inc = new AtomicInteger();

public void increase() {
    inc.getAndIncrement();
}
```

使用`ReentrantLock`改进：

```java
Lock lock = new ReentrantLock();
public void increase() {
    lock.lock();
    try {
        inc++;
    } finally {
        lock.unlock();
    }
}
```





## 二、乐观锁和悲观锁

### 1）悲观锁

悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题（比如共享数据被修改），所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其他线程阻塞，用完后再把资源转让给其它线程。

像Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

```java
Public void performSynchronizedTask(){
  synchronized(this){
    //需要同步的操作
  }
}

public Lock lock = new ReentrantLock();
lock.lock();
try{
  //需要同步的操作
}finally{
  lock.unlock();
}
```

高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁的问题，影响代码的正常运行。



### 2）乐观锁

乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地被执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或CAS算法）。

在Java中`java.util.concurrent.atomic`包下面的原子变量类（比如`AtomicInteger`、`LongAdder`）就是使用了乐观锁的一种实现方式CAS实现的。

![](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC%E5%8E%9F%E5%AD%90%E7%B1%BB%E6%A6%82%E8%A7%88.png)

```java
// LongAdder 在高并发场景下会比 AtomicInteger 和 AtomicLong 的性能更好
// 代价就是会消耗更多的内存空间（空间换时间）
LongAdder sum = new LongAdder();
sum.increment();
```

高并发场景下，乐观锁相比悲观锁来说，不存在锁竞争造成线程阻塞，也不会有死锁的问题，在性能上往往会更胜一筹。但是，如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致CPU飙升。

不过，大量失败重试的问题也是可以解决的，像前面提到的`LongAdder`以空间换时间的方式就解决了这个问题。

理论上来说：

* 悲观锁通常多用于写比较多的情况下（**多写场景**，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如`LongAdder`），也是可以考虑使用乐观锁的，要视实际情况而定。
* 乐观锁通常多用于写比较少的情况下（**多读场景**，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考`java.util.concurrent.atomic`包下面的原子变量类。



### 3）实现乐观锁的方法

乐观锁一般会使用版本号机制或CAS算法实现，CAS算法相对来说更多一些，需要格外注意。



#### 版本号机制

一般是在数据表上加上一个数据版本号`version`字段，表示数据被修改的次数。当数据被修改时，`version`值会加一。当线程A要更新数据值时，在读取数据的同时也会读取`version`值，在提交更新时，**若刚才读取到的`version`值为当前数据库中的`version`值时才更新，**否则重试更新操作，直到更新成功。

**举一个简单的例子**：假设数据库中账户信息表中有一个`version`字段，当前值为1；而当前账户余额字段（`balance`）为$1000。

①操作员A此时将其读出（`version`=1），并从账户余额中扣除\$50（\$100-\$50）。

②在操作员操作的过程中，操作员B也读入此用户信息（`version`=1），并从其账户余额中扣除\$20（\$100-\$20）。

③操作员 A 完成了修改工作，将数据版本号（`version`=1），连同帐户扣除后余额（`balance`=\$50），提交至数据库更新，此时由于提交数据版本等于数据库记录当前版本，数据被更新，数据库记录 `version`更新为2。

④操作员 B 完成了操作，也将版本号（ version=1）试图向数据库提交数据（ balance=$80），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 1 ，数据库记录当前版本也为2 ，不满足 “ 提交版本必须等于当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

这样就避免了操作员B用基于version=1的旧数据修改的结果覆盖操作员A的操作结果的可能。



#### CAS算法

CAS的全称是Compare And Swap（比较与交换），用于实现乐观锁，被广泛应用于各大框架中。CAS的思想很简单，就是用一个预期值与要更新的变量值进行比较，两值相等才会进行更新。

CAS是一个原子操作，底层依赖于一条CPU的原子指令。

> **原子操作**即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。

CAS涉及到三个操作数：

* **V**：要更新的变量值（Var）
* **E**：预期值（Expected）
* **N**：拟写入的新值（New）

当且仅当V的值等于E时，CAS通过原子方式用新值N来更新V的值，如果不等，说明已经有其它线程更新了V，则当前线程放弃更新。

**举一个例子**：线程A要修改变量i的值为6，i原值为1（V=1，E=1，N=6，假设不存在ABA问题）。

1、i与1进行比较，如果相等，则说明没被其他线程修改，可以被设置为6.

2、i与1进行比较，如果不相等，则说明被其他线程修改，当前线程放弃更新，CAS操作失败。

当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

Java语言并没有直接实现CAS，CAS相关的实现时通过C++内联汇编的形式实现的（JNI调用）。因此，CAS的具体实现和操作系统以及CPU都有关系。

`sun.misc`包下的`Unsafe`类提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的CAS操作。

```java
/**
	*  CAS
  * @param o         包含要修改field的对象
  * @param offset    对象中某field的偏移量
  * @param expected  期望值
  * @param update    更新值
  * @return          true | false
  */
public final native boolean compareAndSwapObject(Object o, long offset,  Object expected, Object update);

public final native boolean compareAndSwapInt(Object o, long offset, int expected,int update);

public final native boolean compareAndSwapLong(Object o, long offset, long expected, long update);
```



### 4）乐观锁的问题

####ABA问题

如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到他仍然是A值，那我们就能锁门它的值没有被其它线程修改过了吗？很明显是不能的，<u>因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。</u>这个问题被称为CAS操作的“ABA”问题。

ABA问题的解决思路是在变量前面追加上版本号或者时间戳。JDK1.5以后的AtomicStampedReference类就是用来解决ABA问题的，其中<u>compareAndSet()方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志</u>，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

```java
public boolean compareAndSet(V   expectedReference,
                             V   newReference,
                             int expectedStamp,
                             int newStamp) {
    Pair<V> current = pair;
    return
        expectedReference == current.reference &&
        expectedStamp == current.stamp &&
        ((newReference == current.reference &&
          newStamp == current.stamp) ||
         casPair(current, Pair.of(newReference, newStamp)));
}
```



#### 循环时间长开销大

CAS经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给CPU带来非常大的执行开销。

如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升，pause指令有两个作用：

1、可以**延迟流水线执行指令**，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。

2、可以**避免在退出循环的时候因内存顺序冲**而引起CPU流水线被清空，从而提高CPU的执行效率。



#### 只能保证一个共享变量的原子操作

CAS只对单个共享变量有效，当操作涉及跨多个共享变量时CAS无效。但是从JDK1.5开始，提供了`AtomicReference`类保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作，所以我们可以使用锁或者利用`AtomicReference`类把多个共享变量合并成一个共享变量来操作。



## 三、ReentrantLock

### 1）介绍

`ReentrantLock`实现了`Lock`接口，是一个可重入且独占式的锁，和`synchronized`关键字类似。不过，`ReentrantLock`更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。

```java
public class ReentrantLock implements Lock, java.io.Serializable {}
```

`ReentrantLock`里面有一个内部类`Sync`，`Sync`继承AQS（`AbstractQueuedSynchronizer`），添加锁和释放锁的大部分操作实际上都是在`Sync`中实现的。`Sync`有公平锁`FairSync`和非公平锁`NonfairSync`两个子类。

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/reentrantlock-class-diagram.png)

ReentrantLock默认使用非公平锁，也可以通过构造器来显式的指定使用公平锁。

```java
// 传入一个 boolean 值，true 时为公平锁，false 时为非公平锁
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
```



### 2）公平锁和非公平锁的区别

* **公平锁**：锁被释放之后，先申请的线程先得到锁。性能差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
* **非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。



### 3）synchronized和ReentrantLock的区别

#### 两者都是可重入锁

**可重入锁**也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不是可重入锁，就会造成死锁。

JDK提供的所有现成的Lock实现类，包括`synchronized`关键字锁都是可重入的。

在下面的代码中，`method1()`和`method2()`都被`synchronized`关键字修饰，`method1()`调用了`method2()`。

```java
public class ReentrantLockDemo {
    public synchronized void method1() {
        System.out.println("方法1");
        method2();
    }

    public synchronized void method2() {
        System.out.println("方法2");
    }
}
```

由于`synchronized`锁是可重入的，同一个线程在调用`method1()`时可以直接获得当前对象的锁，执行`method2()`的时候可以再次获取这个对象的锁，不会产生死锁问题。假如`synchronized`是不可冲入锁的话，由于该对象的锁已被当前线程所持有且无法释放，这就导致线程在执行`method2()`时获取锁失败，会出现死锁问题。



#### ReentrantLock比synchronized增加了一些高级功能

相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：

* **等待可中断**：`ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过`lock.lockInterruptibly()`来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
* **可实现公平锁**：`ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可以通过`ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
* **可实现选择性通知（锁可以绑定多个条件）**：`synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。

如果想使用上述功能，那么可以选择`ReentrantLock`。

关于`Condition`接口的补充：

> ``Condition`是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能，也就是在一个Lock对象中可以创建多个`Condition`实例（即对象监视器），线程对象可以注册在指定的`Condition`中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。在使用`notify()/notifyAll()`方法进行通知时，被通知的线程是由JVM选择的，用`ReentrantLock`类结合`Condition`实例可以实现“选择性通知”，这个功能非常重要，而且是`Condition`接口默认提供的。而`synchronized`关键字就相当于整个`Lock`对象中只有一个`Condition`实例，所以线程注册在它一个身上。如果执行`notifyAll()`方法的话就会通知所有处于等待状态的线程，这样会造成很大的效率问题。而`Condition`实例的`signalAll()`方法，只会唤醒注册在该`Condition`实例中的所有等待线程。





### 4）可中断锁和不可中断锁的区别

* 可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后进行其他逻辑处理。`ReentrantLock`就属于是可中断锁。
* 不可中断锁：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。`synchronized`就属于是不可中断锁。






## 四、ReentrantReadWriteLock

`ReentrantReadWriteLock`在实际项目中使用的并不多，面试中也问的比较少，简单了解即可。JDK1.8引入了性能更好的读写锁StampedLock。



### 1）介绍

`ReentrantReadWriteLock`实现了`ReadWriteLock`，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。

```java
public class ReentrantReadWriteLock
        implements ReadWriteLock, java.io.Serializable{
}
public interface ReadWriteLock {
    Lock readLock();
    Lock writeLock();
}
```

* 一般锁进行并发控制的规则：读写互斥、读读互斥、写写互斥。
* 读写锁进行并发控制的规则：读读不互斥、读写互斥、写写互斥（只有读读不互斥）。

ReentrantReadWriteLock其实是两把锁，一把是WriteLock（写锁），一把是ReadLock（读锁）。读锁是共享锁，写锁是独占锁。读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。

和`ReentrantLock`一样，`ReentrantReadWriteLock`底层也是基于AQS实现的。

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/reentrantreadwritelock-class-diagram.png)

`ReentrantReadWriteLock` 也支持公平锁和非公平锁，默认使用非公平锁，可以通过构造器来显示的指定。

````java
// 传入一个 boolean 值，true 时为公平锁，false 时为非公平锁
public ReentrantReadWriteLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
    readerLock = new ReadLock(this);
    writerLock = new WriteLock(this);
}
````



### 2）ReentrantReadWriteLock适合的场景

由于ReentrantReadWriteLock 既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。因此，在**读多写少**的情况下，使用ReentrantReadWriteLock 能够明显提升系统性能。



### 3）共享锁和独占锁的区别

* **共享锁**：一把锁可以被多个线程同时获得。
* **独占锁**：一把锁只能被一个线程获得。




### 4）线程有读锁还能获取写锁吗？

* 在线程持有读锁的情况下，该线程**不能**取得写锁（因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有）。
* 在线程持有写锁的情况下，该线程**可以**继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。




### 5）读锁为什么不能升级为写锁

写锁可以降级为读锁，但是读锁不能升级为写锁。这是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。

另外，还可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。





## 五、StampedLock

### 1）介绍

StampedLock是JDK1.8引入的性能更好的读写锁，不可重入且不支持条件变量Condition。

不同于一般的Lock类，StampedLock并不是直接实现Lock或ReadWriteLock接口，而是基于CLH锁独立实现的（AQS也是基于这个）。

```java
public class StampedLock implements java.io.Serializable {}
```

`StampedLock`提供了三种模式的读写控制模式：读锁、写锁和乐观读。

* **写锁**：独占锁，一把锁只能被一个线程获得。当一个线程获取写锁后，其他请求读锁和写锁的线程必须等到。类似于ReentrantReadWriteLock的写锁，不过这里的写锁是不可重入的。
* **读锁（悲观读）**：共享锁，没有线程获取写锁的情况下，多个线程可以同时持有读锁。如果已经有线程持有写锁，则其他线程请求获取该读锁会被阻塞。类似于`ReentrantReadWriteLock`的读锁，不过这里的读锁是不可重入的。
* **乐观读**：允许多个线程获取乐观读以及读锁。同时允许一个写线程获取写锁。

另外，StampedLock还支持这三种锁在一定条件下进行相互转换。

```java
long tryConvertToWriteLock(long stamp){}
long tryConvertToReadLock(long stamp){}
long tryConvertToOptimisticRead(long stamp){}
```

`StampedLock`在获取锁的时候会返回一个long型的数据戳，该数据戳用于稍后的锁释放参数，如果返回的数据戳为0则表示锁获取失败。当前线程持有了锁再次获取锁还是会返回一个新的数据戳，这也是`StampedLock`不可重入的原因。

```java
// 写锁
public long writeLock() {
    long s, next;  // bypass acquireWrite in fully unlocked case only
    return ((((s = state) & ABITS) == 0L &&
             U.compareAndSwapLong(this, STATE, s, next = s + WBIT)) ?
            next : acquireWrite(false, 0L));
}
// 读锁
public long readLock() {
    long s = state, next;  // bypass acquireRead on common uncontended case
    return ((whead == wtail && (s & ABITS) < RFULL &&
             U.compareAndSwapLong(this, STATE, s, next = s + RUNIT)) ?
            next : acquireRead(false, 0L));
}
// 乐观读
public long tryOptimisticRead() {
    long s;
    return (((s = state) & WBIT) == 0L) ? (s & SBITS) : 0L;
}
```



### 2）StampedLock性能更好的原因

相比于传统读写锁多出来的乐观读是`StampedLock`比`ReadWriteLock`性能更好的关键原因。`StampedLock`的乐观读允许一个写线程获取写锁，所以不会导致所以写线程阻塞，也就是当读多写少的时候，写线程有机会获取写锁，减少了线程饥饿的问题，吞吐量大大提高。



### 3）StampedLock适合的场景

和`ReentrantReadWriteLock`一样，`StampedLock`同样**适合读多写少的业务场景**，可以作为`ReentrantReadWriteLock`的替代品，性能更好。

不过，需要注意的是`StampedLock`**不可重入**，不支持条件变量`Condition`，对中断操作支持也不优化（使用不当容易导致CPU飙升）。如果你需要用到ReetrantLock的一些高级性能，就不太建议使用`StampedLock`了。

另外，StampedLock性能虽好，但**使用起来相对比较麻烦**，一旦使用不当，就会出现生产问题。强烈建议在使用`StampedLock`之前，看看`StampedLock`官方文档中的案例。



### 4）StampedLock的底层原理

StampLock不是直接实现Lock或ReadWriteLock接口，而是基于CLH锁实现的（AQS也是基于这个），CLH锁是对自旋锁的一种改良，是一种隐式的链表队列。StampedLock通过CLH队列进行线程的管理，通过同步状态值state来表示锁的状态和类型。





##六、Atomic原子类





## 七、ThreadLocal

### 1）ThreadLocal的作用

通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？

JDK中自带的`ThreadLocal`类正是为了解决这样的问题。**`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**

如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。它们可以使用`get()`和`set()`方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。

举个简单的例子：两个人去宝物收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。



### 2）如何使用ThreadLocal

```java
import java.text.SimpleDateFormat;
import java.util.Random;

public class ThreadLocalExample implements Runnable{

     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本
    private static final ThreadLocal<SimpleDateFormat> formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat("yyyyMMdd HHmm"));

    public static void main(String[] args) throws InterruptedException {
        ThreadLocalExample obj = new ThreadLocalExample();
        for(int i=0 ; i<10; i++){
            Thread t = new Thread(obj, ""+i);
            Thread.sleep(new Random().nextInt(1000));
            t.start();
        }
    }

    @Override
    public void run() {
        System.out.println("Thread Name= "+Thread.currentThread().getName()+" default Formatter = "+formatter.get().toPattern());
        try {
            Thread.sleep(new Random().nextInt(1000));
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        //formatter pattern is changed here by thread, but it won't reflect to other threads
        formatter.set(new SimpleDateFormat());

        System.out.println("Thread Name= "+Thread.currentThread().getName()+" formatter = "+formatter.get().toPattern());
    }
}
```

输出结果：

```java
Thread Name= 0 default Formatter = yyyyMMdd HHmm
Thread Name= 0 formatter = yy-M-d ah:mm
Thread Name= 1 default Formatter = yyyyMMdd HHmm
Thread Name= 2 default Formatter = yyyyMMdd HHmm
Thread Name= 1 formatter = yy-M-d ah:mm
Thread Name= 3 default Formatter = yyyyMMdd HHmm
Thread Name= 2 formatter = yy-M-d ah:mm
Thread Name= 4 default Formatter = yyyyMMdd HHmm
Thread Name= 3 formatter = yy-M-d ah:mm
Thread Name= 4 formatter = yy-M-d ah:mm
Thread Name= 5 default Formatter = yyyyMMdd HHmm
Thread Name= 5 formatter = yy-M-d ah:mm
Thread Name= 6 default Formatter = yyyyMMdd HHmm
Thread Name= 6 formatter = yy-M-d ah:mm
Thread Name= 7 default Formatter = yyyyMMdd HHmm
Thread Name= 7 formatter = yy-M-d ah:mm
Thread Name= 8 default Formatter = yyyyMMdd HHmm
Thread Name= 9 default Formatter = yyyyMMdd HHmm
Thread Name= 8 formatter = yy-M-d ah:mm
Thread Name= 9 formatter = yy-M-d ah:mm
```

从输出可以看出，虽然Thread-0已经变成了formatter的值，但Thread-1默认格式化值与初始化值相同，其他线程也一样。

上面有一段代码用到了创建ThreadLocal变量的那段代码用到了Java 8的知识，它等于下面这段代码，如果你写了下面这段代码，IDEA会提示你转换为Java 8的格式。因为ThreadLocal类在Java 8中拓展，使用一个新的方法withInitial()将Supplier功能接口作为参数。

```java
private static final ThreadLocal<SimpleDateFormat> formatter = new ThreadLocal<SimpleDateFormat>(){
    @Override
    protected SimpleDateFormat initialValue(){
        return new SimpleDateFormat("yyyyMMdd HHmm");
    }
};
```



### 3）ThreadLocal原理

从Thread类源代码入手：

```java
public class Thread implements Runnable {
    //......
    //与此线程有关的ThreadLocal值。由ThreadLocal类维护
    ThreadLocal.ThreadLocalMap threadLocals = null;

    //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
    //......
}
```

从上面的`Thread`类源代码可以看出`Thread`类中有一个`threadLocals`和一个`inheritableThreadLocals`变量，它们都是`ThreadLocalMap`类型的变量，我们可以把`ThreadLocalMap`理解为`ThreadLocal`类实现的定制化的`HashMap`。默认情况下这两个变量都是null，只有当前线程调用`ThreadLocal`类的`set`或`get`方法时才创建它们，实际上调用这两个方法的时候，我们调用的是`ThreadLocalMap`类对应的`get()`、`set()`方法。

ThreadLocal类的set()、get()方法：

```java
public void set(T value) {
    //获取当前请求的线程
    Thread t = Thread.currentThread();
    //取出 Thread 类内部的 threadLocals 变量(哈希表结构)
    ThreadLocalMap map = getMap(t);
    if (map != null)
        // 将需要存储的值放入到这个哈希表中
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
```

通过上面这些内容，我们足以通过猜测得出结论：**最终的变量是放在了当前线程的`ThreadLocalMap`中，并不是存在`ThreadLocal`上，`ThreadLocal`可以理解为只是`ThreadLocalMap`的封装，传递了变量值。**`ThreadLocal`类中可以通过`Thread.currentThread()`获取到当前线程对象后，直接通过`getMap(Thread t)`可以访问到该线程的`ThreadLocalMap`对象。

**每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为key，Object对象为value的键值对。**

```java
ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
    //......
}
```

比如我们在同一个线程中声明了两个`ThreadLocal`对象的话，`Thread`内部都是使用仅有的那个`ThreadLocalMap`存放数据的，`ThreadLocalMap`的key就是`ThreadLocal`对象，value就是`ThreadLocal`对象调用`set`方法设置的值。

ThreadLocal数据结构如图：

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/threadlocal-data-structure.png)

`ThreadLocalMap`是`ThreadLocal`的静态内部类。

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/thread-local-inner-class.png)



### 4）ThreadLocal内存泄露问题是如何导致的？

`ThreadLocalMap`中使用的key为`ThreadLocal`的弱引用，而value是强引用。所以，如果`ThreadLocal`没有被外部强引用的情况下，在垃圾回收的时候，key会被清理掉，而value不会被清理掉。

这样一来，`ThreadLocalMap`中就会出现key为null的Entry。假如我们不做任何措施的话，value永远无法被GC回收，这个时候就可能会产生内存泄露。`ThreadLocalMap`实现中已经考虑了这种情况，在调用`set()`、`get()`、`remove()`方法的时候，会清理掉key为null的记录。使用完`ThreadLocal`方法后最好手动调用`remove()`方法。

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        value = v;
    }
}
```

> 弱引用、软引用、强引用：
>
> **强引用**是最常见的普通对象引用，只要还有强引用指向对象，对象就存活，垃圾回收器不会处理存活对象。
>
> **软引用**是一种相对强引用弱化了一些的引用，可以让对象豁免一些垃圾收集。当系统内存充足的时候，不会被回收；当系统内存不足的时候，会被回收。软引用一般用于对内存敏感的程序中，比如高速缓存。
>
> **弱引用**需要用java.lang.ref.WeakReference实现，它比软引用的生存期更短，对于弱引用的对象来说，只要垃圾回收机制一运行，不管JVM的内存空间是否够，都会回收该对象的占用内存。





##七、Future

### 1）Future类的作用

`Future`类是异步思想的典型运用，主要用在一些需要执行耗时任务的场景，避免程序一直等到耗时任务执行完成，执行效率太低。具体来说是这样的：当我们执行某一耗时的任务时，可以将这个耗时任务交给一个子线程去异步执行，同时我们可以干点其他事情，不用傻傻等待耗时任务执行完成。等我们的事情干完后，我们再通过`Future`类获取到耗时任务的执行结果。这样一来，程序的执行效率就明显提高了。

这其实就是多线程中经典的**Future模式**，可以将其看作是一种设计模式，核心思想是异步调用，主要用在多线程领域，并非Java语言独有。

在Java中，`Future`类只是一个泛型接口，位于`java.util.concurrent`包下，其中定义了5个方法，主要包括下面这四个功能：

* 取消任务；
* 判断任务是否被取消；
* 判断任务是否已经执行完成；
* 获取任务执行结果。

```java
// V 代表了Future执行的任务返回值的类型
public interface Future<V> {
    // 取消任务执行
    // 成功取消返回 true，否则返回 false
    boolean cancel(boolean mayInterruptIfRunning);
    // 判断任务是否被取消
    boolean isCancelled();
    // 判断任务是否已经执行完成
    boolean isDone();
    // 获取任务执行结果
    V get() throws InterruptedException, ExecutionException;
    // 指定时间内没有返回计算结果就抛出 TimeOutException 异常
    V get(long timeout, TimeUnit unit)

        throws InterruptedException, ExecutionException, TimeoutExceptio

}
```

简单理解就是：有一个任务，提交给了Future来处理。任务执行期间我自己去做任何想做的事情。并且在这期间我还可以取消任务以及获取任务的执行状态。一段时间后，我就可以在Future那里直接取出任务执行结果。



## 2）Callable和Future的关系

可以通过`FutureTask`来理解`Callable`和`Future`之间的关系。

`FutureTask`提供了`Future`接口的基本实现，常用来封装`Callable`和`Runnable`，具有取消任务、查看任务是否执行完成以及获取任务执行结果的方法。`ExecutorService.submit()`方法返回的其实就是`Future`的实现类`FutureTask`。

```java
<T> Future<T> submit(Callable<T> task);
Future<?> submit(Runnable task);
```

FutureTask不光实现了Future接口，还实现了Runnable接口，因此可以作为任务直接被线程执行。

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/completablefuture-class-diagram.jpg)

`FutureTask`有两个构造函数，可传入`Callable`或者`Runnable`对象。实际上，传入`Runnable`对象也会在方法内部转换为`Callable`对象。

```java
public FutureTask(Callable<V> callable) {
    if (callable == null)
        throw new NullPointerException();
    this.callable = callable;
    this.state = NEW;
}
public FutureTask(Runnable runnable, V result) {
    // 通过适配器RunnableAdapter来将Runnable对象runnable转换成Callable对象
    this.callable = Executors.callable(runnable, result);
    this.state = NEW;
}
```

`FutureTask`相当于对`Callable`进行了封装，管理者任务执行的情况，存储了`Callable`的`call`方法的任务执行结果。



### 3）CompletableFuture类的作用

Future在实际使用过程中存在一些局限性比如不支持异步任务的编排组合、获取计算结果的get()方法为阻塞调用。

> **阻塞调用**通常指的是在调用一个函数或方法时，调用者需要等待被调用的函数或方法执行完成并返回结果后才能继续执行。在这个过程中，调用者无法执行其他操作，只能等待。这与非阻塞调用相对，非阻塞调用允许调用者在等待被调用的函数或方法执行完成的同时执行其他操作。

Java 8才被引入CompletableFuture类可以解决Future的这些缺陷。CompletableFuture除了提供了更为好用和强大的Future特性之外，还提供了函数式编程、异步任务编排组合（可以将多个异步任务串联起来，组成一个完整的链式调用）等能力。

CompletableFuture类的定义：

```java
public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {
}
```

可以看到，`CompletableFuture`同时实现了`Future`和`CompletionStage`接口。

![](https://oss.javaguide.cn/github/javaguide/java/concurrent/completablefuture-class-diagram.jpg)

`CompletionStage`接口描述了一个异步计算的阶段。很多计算可以分成多个阶段或步骤，此时可以通过它将所有步骤组合起来，形成异步计算的流水线。

`CompletionStage`接口中的方法比较多，`CompletionStage`的函数式能力就是这个接口赋予的。从这个接口的方法参数你就可以发现其大量使用了java 8引入的函数式编程。

![](https://oss.javaguide.cn/javaguide/image-20210902093026059.png)





## 八、AQS

### 1）介绍

AQS的全称为AbstractQueueSynchronizer，翻译过来的意思就是抽象队列同步器。这个类在java.util.concurrent.locks包下面。

![](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/Java%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/AQS.png)

AQS就是一个抽象类，主要用来构建锁和同步器。

```java
public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable {
}
```

AQS为构建锁和同步器提供了一些通用功能的实现，因此，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue等等皆是基于AQS的。



### 2）AQS的原理

AQS的核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

CLH（）队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。在CLH同步队列中，一个结点表示一个线程，它保存着线程的引用（thread）、当前节点在队列中的状态（waitStatus）、前驱节点（prev）、后继节点（next）。

CLH队列结构如图：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/40cb932a64694262993907ebda6a0bfe~tplv-k3u1fbpfcp-zoom-1.image)

AQS的核心原理图：

![](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/Java%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%EF%BC%9A%E5%B9%B6%E5%8F%91%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/CLH.png)

AQS使用int**成员变量`state`表示同步状态**，通过内置的**线程等待队列**来完成获取资源线程的排队工作。state变量由volatile修饰，用于展示当前临界资源的获锁情况。

```java
// 共享变量，使用volatile修饰保证线程可见性
private volatile int state;
```

另外，状态信息state可以通过protected类型的getState()、setState()和compareAndSetState()进行操作。并且这几个方法都是final修饰的，在子类中无法被重写。

```java
//返回同步状态的当前值
protected final int getState() {
     return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
     state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
      return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

以`ReentrantLock`为例，`state`初始值为0，表示未锁定状态。A线程`lock()`时，会调用`tryAcquire()`独占该锁并将state+1。此后，其他线程再`tryAcquire()`时就会失败，直到A线程`unlock()`到`state=0`（即释放锁）为止，其他线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证state是能回到零态的。

再以`CountDownLatch`为例，任务分为N个子线程去执行，`state`也初始化为N（主要N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后`countDown()`一次，state会CAS（Compare And Swap）减1。等到所有子线程都执行完后（即state=0），会`unpark()`主调用线程，然后主调用线程就会从`await()`函数返回，继续后余动作。



### 3）Semaphore的作用

`synchronized`和`ReentrantLock`都是一次只允许一个线程访问某个资源，而`Semaphore`(信号量)可以用来控制同时访问特定资源的线程数量。

`Semaphore`的使用简单，这里假设有N（N>5）个线程来获取`Semaphore`中的共享资源，下面代码表示同一时刻N个线程中只有5个线程能获取到共享资源，其他线程都会阻塞，只有获取到共享资源的线程才能执行。等到有线程释放了共享资源，其他阻塞的线程才能获取到。

```java
// 初始共享资源数量
final Semaphore semaphore = new Semaphore(5);
// 获取1个许可
semaphore.acquire();
// 释放1个许可
semaphore.release();
```

当初始的资源个数为1的时候，`Semaphore`退化为排他锁。

`Semaphore`有两种模式：

* 公平模式：调用`acquire()`方法的顺序就是获取许可证的顺序，遵循FIFO；
* 非公平模式：抢占式的。

`Semaphore`对应的两个构造方法如下：

```java
public Semaphore(int permits) {
  	sync = new NonfairSync(permits);
}

public Semaphore(int permits, boolean fair) {
  	sync = fair ? new FairSync(permits) : new NonfairSync(permits);
}
```

**这两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。**

`Semaphore`通常用于那些资源有明确访问数量限制的场景，比如限流（仅限于单机模式，实际项目中推荐使用Redis+Lua来做限流）。



### 4）Semaphore的原理

`Semaphore`是共享锁的一种实现，它默认构造AQS的`state`值为`permits`，你可以将`permits`的值理解为许可证的数量，只有拿到许可证的线程才能执行。

调用`semaphore.acquire()`，线程尝试获取许可证，如果`state >= 0`的话，则表示可以获取成功。如果获取成功的话，使用CAS操作去修改`state`的值`state = state - 1`。如果`state < 0`的话，则表示许可证数量不足。此时会创建一个Node节点加入阻塞队列，挂起当前线程。

```java
/**
 *  获取1个许可证
 */
public void acquire() throws InterruptedException {
 	 sync.acquireSharedInterruptibly(1);
}
/**
 * 共享模式下获取许可证，获取成功则返回，失败则加入阻塞队列，挂起线程
 */
public final void acquireSharedInterruptibly(int arg)
    throws InterruptedException {
    if (Thread.interrupted())
      throw new InterruptedException();
        // 尝试获取许可证，arg为获取许可证个数，当可用许可证数减当前获取的许可证数结果小于0,则创建一个节点加入阻塞队列，挂起当前线程。
    if (tryAcquireShared(arg) < 0)
      doAcquireSharedInterruptibly(arg);
}
```

调用semaphore.release();，线程尝试释放许可证，并使用CAS操作去修改state的值state = state + 1。释放许可证成功之后，同时唤醒同步队列中的一个线程。被唤醒的线程会重新尝试去修改state的值state = state - 1，如果state >= 0则获取令牌成功，否则重新进入阻塞队列，挂起线程。

```java
// 释放一个许可证
public void release() {
  	sync.releaseShared(1);
}

// 释放共享锁，同时会唤醒同步队列中的一个线程。
public final boolean releaseShared(int arg) {
    //释放共享锁
    if (tryReleaseShared(arg)) {
      //唤醒同步队列中的一个线程
      doReleaseShared();
      return true;
    }
    return false;
}
```





### 5）CountDownLatch的作用

`CountDownLatch`运行`count`个线程阻塞在一个地方，直至所有线程的任务都执行完毕。

`CountDownLatch`是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当`CountDownLatch`使用完毕后，它不能再次被使用。





### 6）CountDownLatch的原理

`CountDownLatch`是共享锁的一种实现，它默认构造AQS的`state`值为`count`。当线程使用`countDown()`方法时，其实使用了`tryReleaseShare`方法以CAS的操作来减少`state`，直至`state`为0。当调用`await()`方法的时候，如果`state`不为0，那就证明任务还没有执行完毕；`await()`方法就会一直阻塞，也就是说`await()`方法之后的语句不会被执行。然后，`CountDownLatch`会自旋CAS判断`state == 0`，如果`state == 0`的话，就会释放所有等待的线程，`await()`方法之后的语句得到执行。



### 7）CountDownLatch使用场景

`CountDownLatch`的作用就是允许`count`个线程阻塞在一个地方，直至所有线程的任务都执行完毕。之前在项目中有一个使用多线程读取多个文件处理的场景，用到了`CountDownLatch`。具体场景是这样的：

我们要读取处理6个文件，这6个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理。

为此我们定义了一个线程池和`count`为6的`CountDownLatch`对象。使用线程池处理读取任务，每一个线程处理完之后就将`count- 1`，调用`CountDownLatch`对象的`await()`方法，直到所有文件读取完之后，才会接着执行后面的逻辑。

伪代码如下：

```java
public class CountDownLatchExample1 {
    // 处理文件的数量
    private static final int threadCount = 6;

    public static void main(String[] args) throws InterruptedException {
        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {
                try {
                    //处理文件的业务操作
                    //......
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    //表示一个文件已经被完成
                    countDownLatch.countDown();
                }

            });
        }
        countDownLatch.await();
        threadPool.shutdown();
        System.out.println("finish");
    }
}
```

可以改进的地方：

可以使用`CompletableFuture`类来改进，java 8的`CompletableFuture`提供了很多对多线程友好的方法，使用它可以很方便地为我们编写多线程程序，什么异步、串行、并行或者等待所有线程执行完任务什么的都非常方便。

```java
CompletableFuture<Void> task1 =
    CompletableFuture.supplyAsync(()->{
        //自定义业务操作
    });
......
CompletableFuture<Void> task6 =
    CompletableFuture.supplyAsync(()->{
    //自定义业务操作
    });
......
CompletableFuture<Void> headerFuture=CompletableFuture.allOf(task1,.....,task6);

try {
    headerFuture.join();
} catch (Exception ex) {
    //......
}
System.out.println("all done. ");
```

上面的代码还可以继续优化，当任务过多的时候，把每一个task都列出来不太现实，可以考虑通过循环来添加任务。

```java
//文件夹位置
List<String> filePaths = Arrays.asList(...)
// 异步处理所有文件
List<CompletableFuture<String>> fileFutures = filePaths.stream()
    .map(filePath -> doSomeThing(filePath))
    .collect(Collectors.toList());
// 将他们合并起来
CompletableFuture<Void> allFutures = CompletableFuture.allOf(
    fileFutures.toArray(new CompletableFuture[fileFutures.size()])
);
```



### 8）CyclicBarrier的作用

`CyclicBarrier`和`CountDownLatch`非常类似，它也可以实现线程间的技术等待，但是它的功能比`CountDownLatch`更加复杂和强大。主要应用场景和CountDownLatch类似。

> `CountDownLatch`的实现是基于AQS的，而`CyclicBarrier`是基于`ReentrantLock`（`ReentrantLock`也属于AQS同步器）和`Condition`的。

`CyclicBarrier`的字面意思是可循环使用的屏障。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。

`CyclicBarrier`内部通过一个`count`变量作为计数器，`count`的初始值为`parties`属性的初始化值，每当一个线程到了栅栏这里了，那就将计数器减1。如果`count`值为0了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。

```java
//每次拦截的线程数
private final int parties;
//计数器
private int count;
```

**结合源码来看：**

1、`CyclicBarrier`默认的构造方法时`CyclicBarrier(int parties)`，其参数表示屏障拦截的线程数量，每个线程调用`await()`方法告诉`CyclicBarrier`我已经到达了屏障，然后当前线程被阻塞。

```java
public CyclicBarrier(int parties) {
    this(parties, null);
}

public CyclicBarrier(int parties, Runnable barrierAction) {
    if (parties <= 0) throw new IllegalArgumentException();
    this.parties = parties;
    this.count = parties;
    this.barrierCommand = barrierAction;
}
```

其中，`parties`就代表了有拦截的线程的数量，当拦截的线程数量达到这个值就打开栅栏，让所有线程通过。

2、当调用`CyclicBarrier`对象调用`await()`方法时，实际上调用的是`dowait(false, 0L)`方法。`await()`方法就像树立起一个栅栏的行为一样，将线程挡住了，当挡住的线程数量达到`parties`的值时，栅栏才会打开，线程才得以通过执行。

```java
public int await() throws InterruptedException, BrokenBarrierException {
  try {
    	return dowait(false, 0L);
  } catch (TimeoutException toe) {
   	 throw new Error(toe); // cannot happen
  }
}
```

dowait(false, 0L)方法源码分析如下：

```java
    // 当线程数量或者请求数量达到 count 时 await 之后的方法才会被执行。上面的示例中 count 的值就为 5。
    private int count;
    /**
     * Main barrier code, covering the various policies.
     */
    private int dowait(boolean timed, long nanos)
        throws InterruptedException, BrokenBarrierException,
               TimeoutException {
        final ReentrantLock lock = this.lock;
        // 锁住
        lock.lock();
        try {
            final Generation g = generation;

            if (g.broken)
                throw new BrokenBarrierException();

            // 如果线程中断了，抛出异常
            if (Thread.interrupted()) {
                breakBarrier();
                throw new InterruptedException();
            }
            // count减1
            int index = --count;
            // 当 count 数量减为 0 之后说明最后一个线程已经到达栅栏了，也就是达到了可以执行await 方法之后的条件
            if (index == 0) {  // tripped
                boolean ranAction = false;
                try {
                    final Runnable command = barrierCommand;
                    if (command != null)
                        command.run();
                    ranAction = true;
                    // 将 count 重置为 parties 属性的初始化值
                    // 唤醒之前等待的线程
                    // 下一波执行开始
                    nextGeneration();
                    return 0;
                } finally {
                    if (!ranAction)
                        breakBarrier();
                }
            }

            // loop until tripped, broken, interrupted, or timed out
            for (;;) {
                try {
                    if (!timed)
                        trip.await();
                    else if (nanos > 0L)
                        nanos = trip.awaitNanos(nanos);
                } catch (InterruptedException ie) {
                    if (g == generation && ! g.broken) {
                        breakBarrier();
                        throw ie;
                    } else {
                        // We're about to finish waiting even if we had not
                        // been interrupted, so this interrupt is deemed to
                        // "belong" to subsequent execution.
                        Thread.currentThread().interrupt();
                    }
                }

                if (g.broken)
                    throw new BrokenBarrierException();

                if (g != generation)
                    return index;

                if (timed && nanos <= 0L) {
                    breakBarrier();
                    throw new TimeoutException();
                }
            }
        } finally {
            lock.unlock();
        }
    }
```



















